1
00:00:00,360 --> 00:00:03,227
Now that you've seen what
a simple convnet looks like,

이제는 간단한 convnet이 어떻게 보이는지 보았으므로,

2
00:00:03,227 --> 00:00:05,794
there are many things that
we can do to improve it.

우리가 개선 할 수있는 많은 것들이 있습니다.

3
00:00:05,794 --> 00:00:10,111
We're going to talk about three of them,
pooling, one by one convolutions and
우리는 세 가지에 대해 이야기 할 것입니다. 풀링,

4
00:00:10,112 --> 00:00:13,821
something a bit more advanced
called the inception architecture.
하나씩의 컨볼 루션 및 초기 아키텍처라는 조금 더 진보 된 것입니다.

5
00:00:13,821 --> 00:00:17,740
The first improvement is a better way
to reduce the spatial extent of your
첫 번째 개선은 컨벌루션 피라미드에서 기능 맵의

6
00:00:17,740 --> 00:00:20,790
feature maps in
the convolutional pyramid.
공간 범위를 줄이는 더 좋은 방법입니다.

7
00:00:20,790 --> 00:00:25,540
Until now, we've used striding to shift
the filters by a few pixel each time and
지금까지 우리는 스트라이드를 사용하여

8
00:00:25,540 --> 00:00:27,570
reduce the future map size.
매 픽셀 몇 픽셀 씩 필터를 조정하고 미래 맵 크기를 줄입니다.

9
00:00:27,570 --> 00:00:30,860
This is a very aggressive
way to downsample an image.
이것은 이미지를 다운 샘플링하는 매우 공격적인 방법입니다.

10
00:00:30,860 --> 00:00:32,280
It removes a lot of information.
그것은 많은 정보를 제거합니다.

11
00:00:33,600 --> 00:00:36,660
What if instead of skipping
one in every two convolutions,
두 번의 회선에서 하나를 건너 뛰는 대신에, 우리는 여전히 아주 작은 보폭,

12
00:00:36,660 --> 00:00:40,690
we still ran with a very small stride,
say for example one.
예를 들면 하나를 가지고 달렸습니다.

13
00:00:40,690 --> 00:00:44,980
But then took all the convolutions in a
neighborhood and combined them somehow.
그런 다음 이웃에있는 모든 회선을 가져 와서 어떻게 든 결합했습니다.

14
00:00:46,540 --> 00:00:50,780
That operation is called pooling, and
there are a few ways to go about it.
그 작업을 풀링 (pooling)이라고하며, 여기에 대해서는 몇 가지 방법이 있습니다.

15
00:00:50,780 --> 00:00:52,850
The most common is max pooling.
가장 일반적인 것은 최대 풀링입니다.

16
00:00:52,850 --> 00:00:56,500
At every point in the future map,
look at a small neighborhood around that
미래지도의 모든 지점에서 그 지점 주변의 작은 이웃을보고 

17
00:00:56,500 --> 00:01:00,910
point and compute the maximum
of all the responses around it.
그 지점의 모든 응답의 최대 값을 계산하십시오.

18
00:01:00,910 --> 00:01:03,800
There are some advantages
to using max pooling.
최대 풀링을 사용하면 몇 가지 장점이 있습니다.

19
00:01:03,800 --> 00:01:06,399
First, it doesn't add to
your number of parameters.
첫째, 매개 변수의 수가 증가하지 않습니다.

20
00:01:06,400 --> 00:01:08,160
So you don't risk
an increasing over fitting.
따라서 지나치게 피팅하는 위험은 없습니다.

21
00:01:09,190 --> 00:01:11,660
Second, it simply often
yields more accurate models.
둘째,보다 정확한 모델을 산출하는 경우가 많습니다.

22
00:01:12,880 --> 00:01:16,899
However, since the convolutions that
run below run at a lower stride,
그러나, 그 convolutions 때문에 아래보다 낮은 보폭에서 실행하면

23
00:01:16,900 --> 00:01:19,290
the model then becomes a lot
more expensive to compute.
모델은 계산하기가 훨씬 더 비쌉니다.

24
00:01:20,400 --> 00:01:23,480
And now you have even more hyper
parameters to worry about.
이제는 더 많은 하이퍼 매개 변수가 걱정됩니다.

25
00:01:23,480 --> 00:01:26,850
The pooling region size, and
the pooling stride, and no,
풀링 영역 크기와 풀링 스트라이드는 

26
00:01:26,850 --> 00:01:27,880
they don't have to be the same.
동일 할 필요는 없습니다.

27
00:01:28,910 --> 00:01:30,479
A very typical architecture for
규약된 전형적인 아키텍처는 

28
00:01:30,480 --> 00:01:33,910
a covenant is a few layers
alternating convolutions and
컨볼루션과 최대 풀링을 번갈아 가며 몇 개의 레이어를

29
00:01:33,910 --> 00:01:37,660
max pooling, followed by a few
fully connected layers at the top.
연결 한 다음 맨 위에 몇 개의 완전히 연결된 레이어를 연결 한 것입니다.

30
00:01:38,670 --> 00:01:43,472
The first famous model to use this
architecture was LENET-5 designed by
이 아키텍처를 사용하는 최초의 유명한 모델은 1998년

31
00:01:43,472 --> 00:01:47,356
Yann Lecun to the character
recognition back in 1998.
Yann Lecun이 문자 인식으로 설계 한 LENET-5입니다.

32
00:01:47,356 --> 00:01:50,276
Modern convolutional networks
such as ALEXNET, which

33
00:01:50,276 --> 00:01:54,687
famously won the competitive ImageNet
object recognition challenge in 2012,

34
00:01:54,687 --> 00:01:57,559
used a very similar architecture
with a few wrinkles.

35
00:01:58,810 --> 00:02:02,250
Another notable form of
pooling is average pooling.

36
00:02:02,250 --> 00:02:04,20
Instead of taking the max,

37
00:02:04,20 --> 00:02:08,970
just take an average over the window
of pixels around a specific location.

38
00:02:08,970 --> 00:02:12,423
It's a little bit like providing
a blurred low resolution view of

39
00:02:12,423 --> 00:02:13,694
the feature map below.

40
00:02:13,694 --> 00:02:15,500
We're going to take
advantage of that shortly.

